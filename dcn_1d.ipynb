{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","# DATASET AND DATALOADER FOR GAUSSIAN SEQUENCE\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","\n","import torch\n","import numpy as np\n","import random\n","from torch.utils.data import DataLoader\n","\n","class IndexedGaussianSequence:\n","    def __init__(self, n, center, std, device='cpu'):\n","        \"\"\"\n","        Args:\n","            n (int): Length of the sequence.\n","            center (int): Position where Gaussian is centered.\n","            std (float): Standard deviation of the Gaussian.\n","            device (str): Device where the result should be moved.\n","        \"\"\"\n","        self.n = n\n","        self.center = center\n","        self.std = std\n","        self.device = device\n","\n","    def __getitem__(self, index):\n","        if 0 <= index < self.n:\n","            value = np.exp(-(index - self.center) ** 2 / (2 * self.std ** 2))\n","        else:\n","            value = np.exp(-(index - self.center) ** 2 / (2 * self.std ** 2)) # TODO for non-synthetic image or sequence we need account for out of bound index for now it is fine \n","\n","        return torch.tensor(value).to(self.device)\n","\n","    def __len__(self):\n","        return self.n\n","\n","class GaussianSequenceDataset(torch.utils.data.Dataset):\n","    def __init__(self, n, p, q, size, std, device='cpu'):\n","        \"\"\"\n","        Args:\n","            n (int): Length of the sequence.\n","            p (int): Position for label 0 where Gaussian is centered.\n","            q (int): Position for label 1 where Gaussian is centered.\n","            size (int): Number of samples in the dataset.\n","            std (float): Standard deviation of the Gaussian.\n","            device (str): Device where the result should be moved.\n","        \"\"\"\n","        self.n = n\n","        self.p = p\n","        self.q = q\n","        self.size = size\n","        self.std = std\n","        self.device = device\n","\n","    def __len__(self):\n","        return self.size\n","\n","    def __getitem__(self, idx):\n","        label = idx % 2  # Alternate between labels 0 and 1\n","\n","        if label == 0:\n","            sequence = IndexedGaussianSequence(self.n, self.p, self.std, self.device)\n","        else:\n","            sequence = IndexedGaussianSequence(self.n, self.q, self.std, self.device)\n","        \n","        return sequence, label\n","\n","def custom_collate_fn(batch):\n","    sequences, labels = zip(*batch)  # Unzip the batch into sequences and labels\n","    return list(sequences), torch.tensor(labels)\n","\n","### NOTE this is a usage example here -- essentially if you define your own custom collate function that basically just trivially list-batch the input, welp, list-batch then bang! you're done!\n","# Create a DataLoader with the custom collate function\n","# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n","\n","\n","\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","# DIFFERENTIABLE INDEXING FOR ARBITRARY INDEXABLE OBJECTS\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","\n","import torch\n","\n","class DifferentiableIndexFunction(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, indexable_obj, indices):\n","        device = indices.device  # Ensure we know the device where indices are located\n","\n","        # Floor and ceil indices\n","        indices_floor = torch.floor(indices).long()\n","        indices_ceil = torch.ceil(indices).long()\n","\n","        # Extract values at the floor and ceil indices\n","        values_floor = torch.tensor([indexable_obj[i.item()] for i in indices_floor], dtype=torch.float32).to(device)\n","        values_ceil = torch.tensor([indexable_obj[i.item()] for i in indices_ceil], dtype=torch.float32).to(device)\n","\n","        # Save tensors for the backward pass\n","        ctx.save_for_backward(indices, values_floor, values_ceil)\n","\n","        # Linear interpolation\n","        weights_floor = indices - indices_floor.float().to(device) # TODO optimize the to(device) call\n","        weights_ceil = indices_ceil.float().to(device) - indices # TODO optimize the to(device) call\n","\n","        output = weights_ceil * values_floor + weights_floor * values_ceil\n","\n","        return output\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        # Retrieve saved tensors\n","        indices, values_floor, values_ceil = ctx.saved_tensors\n","\n","        # Calculate gradients for indices\n","        grad_indices = (values_ceil - values_floor) * grad_output\n","\n","        # No gradient for indexable_obj\n","        grad_indexable_obj = None\n","\n","        return grad_indexable_obj, grad_indices\n","\n","\n","class DifferentiableIndexFunctionBatch(torch.autograd.Function):\n","    @staticmethod\n","    def forward(ctx, indexable_objs, indices_batch):\n","        device = indices_batch.device  # Ensure we know the device where indices_batch are located\n","\n","        # Ensure that indexable_objs has the same length as the batch dimension\n","        assert len(indexable_objs) == indices_batch.shape[0], f\"indexable_objs length {len(indexable_objs)} must match batch dimension {indices_batch.shape[0]}\"\n","\n","        # Result container\n","        output_batch = []\n","        saved_tensors = []\n","\n","        # Process each item in the batch\n","        for i in range(len(indexable_objs)):\n","            indices = indices_batch[i]\n","\n","\n","            # Floor and ceil indices\n","            indices_floor = torch.floor(indices).long()\n","            indices_ceil = torch.ceil(indices).long()\n","\n","            # Extract values at the floor and ceil indices individually\n","            values_floor = torch.tensor([indexable_objs[i][idx.item()] for idx in indices_floor], dtype=torch.float32).to(device)\n","            values_ceil = torch.tensor([indexable_objs[i][idx.item()] for idx in indices_ceil], dtype=torch.float32).to(device)\n","\n","            # Save tensors for backward pass\n","            saved_tensors.append((indices, values_floor, values_ceil))\n","\n","            # Linear interpolation\n","            weights_floor = indices - indices_floor.float().to(device)\n","            weights_ceil = indices_ceil.float().to(device) - indices\n","\n","            output = weights_ceil * values_floor + weights_floor * values_ceil\n","            output_batch.append(output)\n","\n","        # Save all necessary tensors for the backward pass\n","        ctx.save_for_backward(*[t for sublist in saved_tensors for t in sublist])\n","\n","        # Stack output for the batch\n","        return torch.stack(output_batch)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output_batch):\n","        # Retrieve saved tensors\n","        saved_tensors = ctx.saved_tensors\n","\n","        # Gradient container for indices_batch\n","        grad_indices_batch = []\n","\n","        # Process each item in the batch\n","        num_saved_tensors = 3  # indices, values_floor, values_ceil per batch item\n","        for i in range(0, len(saved_tensors), num_saved_tensors):\n","            indices, values_floor, values_ceil = saved_tensors[i:i+num_saved_tensors]\n","            grad_output = grad_output_batch[i // num_saved_tensors]\n","\n","            # Calculate gradients for indices\n","            grad_indices = (values_ceil - values_floor) * grad_output\n","            grad_indices_batch.append(grad_indices)\n","\n","        # No gradient for indexable_objs\n","        grad_indexable_objs = None\n","\n","        # print(\"grad_indices_batch\", grad_indices_batch)\n","\n","        # Stack gradients for the batch\n","        return grad_indexable_objs, torch.stack(grad_indices_batch)\n","\n","# Wrapper function to use in your model\n","def differentiable_index_batch(indexable_objs, indices_batch):\n","    return DifferentiableIndexFunctionBatch.apply(indexable_objs, indices_batch)\n","\n","\n","\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","# SIMPLE TWO PARAMETER MODEL FOR ESTIMATING THE GAUSSIAN CENTER\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","\n","import torch\n","import torch.nn as nn\n","\n","class PQEstimatorModel(nn.Module):\n","    def __init__(self, sequence_length):\n","        super(PQEstimatorModel, self).__init__()\n","        # Initialize p and q as learnable parametersm initalized uniform float at random between 0 and sequence_length-1\n","        random_number_1 = random.uniform(0, sequence_length-1)\n","        random_number_2 = random.uniform(0, sequence_length-1)\n","        self.p = nn.Parameter(torch.tensor(random_number_1))  \n","        self.q = nn.Parameter(torch.tensor(random_number_2))\n","\n","        self.diff_index = differentiable_index_batch\n","\n","    def forward(self, sequence_batch):\n","        \n","        # print(self.p, self.q)\n","\n","        # Calculate p and q values using the differentiable index function\n","        # first put p and q together [p, q] and the repeat it for the batch size which is the length of the sequence_batch\n","        pq_matrix = torch.stack([self.p, self.q]).repeat(len(sequence_batch), 1)\n","\n","        pq_value = self.diff_index(sequence_batch, pq_matrix)\n","\n","        return pq_value\n","\n","\n","\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","# PQ LOSS FUNCTION\n","####################################################################################################################################\n","####################################################################################################################################\n","####################################################################################################################################\n","\n","import torch\n","import torch.nn as nn\n","\n","class PQLoss(nn.Module):\n","    def __init__(self, reduction='mean'):\n","        super(PQLoss, self).__init__()\n","        self.reduction = reduction\n","\n","    def forward(self, pq_matrix):\n","        # Ensure the input is of shape (batch_size, 2)\n","        assert pq_matrix.shape[1] == 2, \"Input pq_matrix must have shape (batch_size, 2)\"\n","\n","        # Split the pq_matrix into p_val and q_val\n","        p_val = pq_matrix[:, 0]\n","        q_val = pq_matrix[:, 1]\n","\n","        # Calculate the loss for each item in the batch\n","        loss = (1 - p_val)**2 + (1 - q_val)**2\n","\n","        # Apply the specified reduction (mean or sum or none)\n","        if self.reduction == 'mean':\n","            return loss.mean()  # Average over the batch\n","        elif self.reduction == 'sum':\n","            return loss.sum()  # Sum over the batch\n","        else:  # 'none'\n","            return loss  # Return the loss for each element in the batch"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/100], Loss: 0.8150\n","Epoch [2/100], Loss: 0.8025\n","Epoch [3/100], Loss: 0.7905\n","Epoch [4/100], Loss: 0.7791\n","Epoch [5/100], Loss: 0.7683\n","Epoch [6/100], Loss: 0.7583\n","Epoch [7/100], Loss: 0.7492\n","Epoch [8/100], Loss: 0.7411\n","Epoch [9/100], Loss: 0.7339\n","Epoch [10/100], Loss: 0.7277\n","Epoch [11/100], Loss: 0.7224\n","Epoch [12/100], Loss: 0.7181\n","Epoch [13/100], Loss: 0.7147\n","Epoch [14/100], Loss: 0.7122\n","Epoch [15/100], Loss: 0.7105\n","Epoch [16/100], Loss: 0.7094\n","Epoch [17/100], Loss: 0.7087\n","Epoch [18/100], Loss: 0.7087\n","Epoch [19/100], Loss: 0.7089\n","Epoch [20/100], Loss: 0.7094\n","Epoch [21/100], Loss: 0.7100\n","Epoch [22/100], Loss: 0.7107\n","Epoch [23/100], Loss: 0.7113\n","Epoch [24/100], Loss: 0.7119\n","Epoch [25/100], Loss: 0.7124\n","Epoch [26/100], Loss: 0.7126\n","Epoch [27/100], Loss: 0.7128\n","Epoch [28/100], Loss: 0.7128\n","Epoch [29/100], Loss: 0.7127\n","Epoch [30/100], Loss: 0.7125\n","Epoch [31/100], Loss: 0.7122\n","Epoch [32/100], Loss: 0.7119\n","Epoch [33/100], Loss: 0.7114\n","Epoch [34/100], Loss: 0.7109\n","Epoch [35/100], Loss: 0.7104\n","Epoch [36/100], Loss: 0.7101\n","Epoch [37/100], Loss: 0.7096\n","Epoch [38/100], Loss: 0.7093\n","Epoch [39/100], Loss: 0.7090\n","Epoch [40/100], Loss: 0.7088\n","Epoch [41/100], Loss: 0.7086\n","Epoch [42/100], Loss: 0.7086\n","Epoch [43/100], Loss: 0.7085\n","Epoch [44/100], Loss: 0.7086\n","Epoch [45/100], Loss: 0.7086\n","Epoch [46/100], Loss: 0.7087\n","Epoch [47/100], Loss: 0.7088\n","Epoch [48/100], Loss: 0.7088\n","Epoch [49/100], Loss: 0.7088\n","Epoch [50/100], Loss: 0.7089\n","Epoch [51/100], Loss: 0.7089\n","Epoch [52/100], Loss: 0.7090\n","Epoch [53/100], Loss: 0.7089\n","Epoch [54/100], Loss: 0.7089\n","Epoch [55/100], Loss: 0.7089\n","Epoch [56/100], Loss: 0.7088\n","Epoch [57/100], Loss: 0.7088\n","Epoch [58/100], Loss: 0.7088\n","Epoch [59/100], Loss: 0.7088\n","Epoch [60/100], Loss: 0.7088\n","Epoch [61/100], Loss: 0.7088\n","Epoch [62/100], Loss: 0.7087\n","Epoch [63/100], Loss: 0.7087\n","Epoch [64/100], Loss: 0.7086\n","Epoch [65/100], Loss: 0.7086\n","Epoch [66/100], Loss: 0.7085\n","Epoch [67/100], Loss: 0.7085\n","Epoch [68/100], Loss: 0.7085\n","Epoch [69/100], Loss: 0.7085\n","Epoch [70/100], Loss: 0.7085\n","Epoch [71/100], Loss: 0.7085\n","Epoch [72/100], Loss: 0.7085\n","Epoch [73/100], Loss: 0.7085\n","Epoch [74/100], Loss: 0.7085\n","Epoch [75/100], Loss: 0.7085\n","Epoch [76/100], Loss: 0.7085\n","Epoch [77/100], Loss: 0.7085\n","Epoch [78/100], Loss: 0.7084\n","Epoch [79/100], Loss: 0.7084\n","Epoch [80/100], Loss: 0.7084\n","Epoch [81/100], Loss: 0.7084\n","Epoch [82/100], Loss: 0.7085\n","Epoch [83/100], Loss: 0.7085\n","Epoch [84/100], Loss: 0.7085\n","Epoch [85/100], Loss: 0.7085\n","Epoch [86/100], Loss: 0.7085\n","Epoch [87/100], Loss: 0.7084\n","Epoch [88/100], Loss: 0.7084\n","Epoch [89/100], Loss: 0.7084\n","Epoch [90/100], Loss: 0.7084\n","Epoch [91/100], Loss: 0.7084\n","Epoch [92/100], Loss: 0.7084\n","Epoch [93/100], Loss: 0.7084\n","Epoch [94/100], Loss: 0.7084\n","Epoch [95/100], Loss: 0.7084\n","Epoch [96/100], Loss: 0.7084\n","Epoch [97/100], Loss: 0.7084\n","Epoch [98/100], Loss: 0.7084\n","Epoch [99/100], Loss: 0.7084\n","Epoch [100/100], Loss: 0.7084\n","Training complete.\n","Initial p value: 65.16217803955078\n","Initial q value: 63.69261932373047\n","Final p value: 49.472373962402344\n","Final q value: 49.540977478027344\n","True p value: 22.6\n","True q value: 76.4\n"]}],"source":["import torch\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","\n","# Training settings\n","n = 100  # Length of the sequence\n","p = 22.6  # Center of the Gaussian for label 0\n","q = 76.4  # Center of the Gaussian for label 1\n","size = 32  # Size of the dataset\n","std = 20  # Standard deviation of the Gaussian\n","batch_size = 32\n","sequence_length = n\n","epochs = 100\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Set up the dataset and DataLoader\n","dataset = GaussianSequenceDataset(n, p, q, size, std, device=device)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n","\n","# Initialize the model, loss function, and optimizer\n","model = PQEstimatorModel(sequence_length=sequence_length).to(device)\n","loss_fn = PQLoss(reduction='mean')\n","optimizer = optim.Adam(model.parameters(), lr=1)\n","\n","initial_p = model.p.item()\n","initial_q = model.q.item()\n","\n","# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    \n","    for sequences, labels in dataloader:\n","        # Forward pass\n","        pq_values = model(sequences)\n","        \n","        # Compute loss\n","        loss = loss_fn(pq_values)\n","        \n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Accumulate loss\n","        running_loss += loss.item()\n","\n","    # Print average loss for the epoch\n","    avg_loss = running_loss / len(dataloader)\n","    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n","\n","print(\"Training complete.\")\n","\n","print(\"Initial p value:\", initial_p)\n","print(\"Initial q value:\", initial_q)\n","\n","# print the final p and q values\n","print(\"Final p value:\", model.p.item())\n","print(\"Final q value:\", model.q.item())\n","\n","# print the true p and q values\n","print(\"True p value:\", p)\n","print(\"True q value:\", q)\n"]}],"metadata":{"kernelspec":{"display_name":"neo-wsiarch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":2}
